{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pIg5R3Jzwu12"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V_bwPXLVxA4N"
   },
   "outputs": [],
   "source": [
    "class CVAE(nn.Module):\n",
    "    def __init__(self, input_size, latent_size, class_size):\n",
    "        super(CVAE, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.class_size = class_size\n",
    "        self.latent_size = latent_size\n",
    "        self.units = 400\n",
    "\n",
    "        ######################################################\n",
    "        ###              START OF YOUR CODE                ###\n",
    "        ######################################################\n",
    "        ### Define a three layer neural network architecture #\n",
    "        ### for the recognition_model                        #\n",
    "        ######################################################\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.affine_1 = nn.Linear(input_size + class_size, self.units)\n",
    "        self.affine_2 = nn.Linear(self.units, self.units)\n",
    "        \n",
    "        self.mu = nn.Linear(self.units, latent_size)\n",
    "        self.logvar = nn.Linear(self.units, latent_size)\n",
    "\n",
    "        ######################################################\n",
    "        ###               END OF YOUR CODE                 ###\n",
    "        ######################################################\n",
    "\n",
    "        ######################################################\n",
    "        ###              START OF YOUR CODE                ###\n",
    "        ######################################################\n",
    "        ### Define a three layer neural network architecture #\n",
    "        ### for the generation_model                         #\n",
    "        ######################################################\n",
    "        self.affine_3 = nn.Linear(latent_size + class_size, self.units)\n",
    "        self.affine_4 = nn.Linear(self.units, self.units)\n",
    "        \n",
    "        self.output = nn.Linear(self.units, input_size)\n",
    "\n",
    "        ######################################################\n",
    "        ###               END OF YOUR CODE                 ###\n",
    "        ######################################################\n",
    "\n",
    "\n",
    "\n",
    "    def recognition_model(self, x, c):\n",
    "        \"\"\"\n",
    "        Computes the parameters of the posterior distribution q(z | x, c) using the\n",
    "        recognition network defined in the constructor\n",
    "    \n",
    "        Inputs:\n",
    "        - x: PyTorch Variable of shape (batch_size, input_size) for the input data\n",
    "        - c: PyTorch Variable of shape (batch_size, num_classes) for the input data class\n",
    "        \n",
    "        Returns:\n",
    "        - mu: PyTorch Variable of shape (batch_size, latent_size) for the posterior mu\n",
    "        - logvar PyTorch Variable of shape (batch_size, latent_size) for the posterior\n",
    "          variance in log space\n",
    "        \"\"\"\n",
    "        ###########################\n",
    "        ######### TO DO ###########\n",
    "        ###########################\n",
    "        mu = None\n",
    "        logvar = None\n",
    "        \n",
    "        inputs = torch.cat([x,c], 1)\n",
    "        h_1 = self.relu(self.affine_1(inputs))\n",
    "        h_2 = self.relu(self.affine_2(h_1))\n",
    "        \n",
    "        mu = self.mu(h_2)\n",
    "        logvar = self.logvar(h_2)\n",
    "        \n",
    "        return mu, logvar\n",
    "\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        eps = Variable(std.data.new(std.size()).normal_())\n",
    "        return eps.mul(std) + mu\n",
    "\n",
    "    def generation_model(self, z, c): # P(x|z, c)\n",
    "        \"\"\"\n",
    "        Computes the generation output from the generative distribution p(x | z, c)\n",
    "        using the generation network defined in the constructor\n",
    "    \n",
    "        Inputs:\n",
    "        - z: PyTorch Variable of shape (batch_size, latent_size) for the latent vector\n",
    "        - c: PyTorch Variable of shape (batch_size, num_classes) for the input data class\n",
    "        \n",
    "        Returns:\n",
    "        - x_hat: PyTorch Variable of shape (batch_size, input_size) for the generated data\n",
    "        \"\"\"\n",
    "        ###########################\n",
    "        ######### TO DO ###########\n",
    "        ###########################\n",
    "        x_hat = None\n",
    "        \n",
    "        inputs = torch.cat([z,c], 1)\n",
    "        h_3 = self.relu(self.affine_3(inputs))\n",
    "        h_4 = self.relu(self.affine_4(h_3))\n",
    "        \n",
    "        x_hat = self.sigmoid(self.output(h_4))\n",
    "        \n",
    "        return x_hat\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        \"\"\"\n",
    "        Performs the inference and generation steps of the CVAE model using\n",
    "        the recognition_model, reparametrization trick, and generation_model\n",
    "    \n",
    "        Inputs:\n",
    "        - x: PyTorch Variable of shape (batch_size, input_size) for the input data\n",
    "        - c: PyTorch Variable of shape (batch_size, num_classes) for the input data class\n",
    "        \n",
    "        Returns:\n",
    "        - x_hat: PyTorch Variable of shape (batch_size, input_size) for the generated data\n",
    "        - mu: PyTorch Variable of shape (batch_size, latent_size) for the posterior mu\n",
    "        - logvar: PyTorch Variable of shape (batch_size, latent_size)\n",
    "                  for the posterior logvar\n",
    "        \"\"\"\n",
    "        ###########################\n",
    "        ######### TO DO ###########\n",
    "        ###########################\n",
    "        x_hat = None\n",
    "        mu = None\n",
    "        logvar = None\n",
    "        \n",
    "        mu, logvar = self.recognition_model(x, c)\n",
    "        p = self.reparametrize(mu, logvar)\n",
    "        x_hat = self.generation_model(p, c)\n",
    "        \n",
    "        return x_hat, mu, logvar\n",
    "\n",
    "\n",
    "def to_var(x, use_cuda):\n",
    "    x = Variable(x)\n",
    "    if use_cuda:\n",
    "        x = x.cuda()\n",
    "    return x\n",
    "\n",
    "\n",
    "def one_hot(labels, class_size, use_cuda):\n",
    "    targets = torch.zeros(labels.size(0), class_size)\n",
    "    for i, label in enumerate(labels):\n",
    "        targets[i, label] = 1\n",
    "    return to_var(targets, use_cuda)\n",
    "\n",
    "\n",
    "def train(epoch, model, train_loader, optimizer, num_classes, use_cuda):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        data = to_var(data, use_cuda).view(data.shape[0], -1)\n",
    "        labels = one_hot(labels, num_classes, use_cuda)\n",
    "        recon_batch, mu, logvar = model(data, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.data\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.data / len(data)))\n",
    "\n",
    "\n",
    "def loss_function(x_hat, x, mu, logvar):\n",
    "    \"\"\"\n",
    "    Computes the negative variational lowerbound for conditional vae\n",
    "    Note: We compute -lowerbound because we optimize the network by minimizing a loss\n",
    "\n",
    "    Inputs:\n",
    "    - x_hat: PyTorch Variable of shape (batch_size, input_size) for the generated data\n",
    "    - x: PyTorch Variable of shape (batch_size, input_size) for the real data\n",
    "    - mu: PyTorch Variable of shape (batch_size, latent_size) for the posterior mu\n",
    "    - logvar: PyTorch Variable of shape (batch_size, latent_size) for the posterior logvar\n",
    "    \n",
    "    Returns:\n",
    "    - loss: PyTorch Variable containing the (scalar) loss for the negative lowerbound.\n",
    "    \"\"\"\n",
    "    ###########################\n",
    "    ######### TO DO ###########\n",
    "    ###########################\n",
    "    loss = None    \n",
    "    batch_size, input_size = x.shape\n",
    "    loss1 = F.binary_cross_entropy(x_hat, x.view(-1, input_size), size_average = False)\n",
    "    loss2 = 0.5 * torch.sum(torch.exp(logvar) + mu**2 - 1 - logvar)\n",
    "    loss = loss1 + loss2\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 308,
     "status": "error",
     "timestamp": 1584547363247,
     "user": {
      "displayName": "Sungryull Sohn",
      "photoUrl": "",
      "userId": "06647518667646069751"
     },
     "user_tz": 240
    },
    "id": "8iBwmYlM4pH7",
    "outputId": "bc8489d1-3d1c-4308-e5c9-54dd35454d33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/10000 (0%)]\tLoss: 543.240723\n",
      "Train Epoch: 1 [3200/10000 (32%)]\tLoss: 201.134949\n",
      "Train Epoch: 1 [6400/10000 (64%)]\tLoss: 177.762085\n",
      "Train Epoch: 1 [9600/10000 (96%)]\tLoss: 151.249939\n",
      "Train Epoch: 2 [0/10000 (0%)]\tLoss: 160.465515\n",
      "Train Epoch: 2 [3200/10000 (32%)]\tLoss: 152.169418\n",
      "Train Epoch: 2 [6400/10000 (64%)]\tLoss: 139.108032\n",
      "Train Epoch: 2 [9600/10000 (96%)]\tLoss: 133.159058\n",
      "Train Epoch: 3 [0/10000 (0%)]\tLoss: 130.044952\n",
      "Train Epoch: 3 [3200/10000 (32%)]\tLoss: 133.692581\n",
      "Train Epoch: 3 [6400/10000 (64%)]\tLoss: 137.082275\n",
      "Train Epoch: 3 [9600/10000 (96%)]\tLoss: 131.122971\n",
      "Train Epoch: 4 [0/10000 (0%)]\tLoss: 123.993256\n",
      "Train Epoch: 4 [3200/10000 (32%)]\tLoss: 122.653526\n",
      "Train Epoch: 4 [6400/10000 (64%)]\tLoss: 120.095825\n",
      "Train Epoch: 4 [9600/10000 (96%)]\tLoss: 124.420311\n",
      "Train Epoch: 5 [0/10000 (0%)]\tLoss: 118.155006\n",
      "Train Epoch: 5 [3200/10000 (32%)]\tLoss: 105.047661\n",
      "Train Epoch: 5 [6400/10000 (64%)]\tLoss: 120.164001\n",
      "Train Epoch: 5 [9600/10000 (96%)]\tLoss: 119.830498\n",
      "Train Epoch: 6 [0/10000 (0%)]\tLoss: 126.276810\n",
      "Train Epoch: 6 [3200/10000 (32%)]\tLoss: 108.025223\n",
      "Train Epoch: 6 [6400/10000 (64%)]\tLoss: 120.615601\n",
      "Train Epoch: 6 [9600/10000 (96%)]\tLoss: 114.179100\n",
      "Train Epoch: 7 [0/10000 (0%)]\tLoss: 105.456398\n",
      "Train Epoch: 7 [3200/10000 (32%)]\tLoss: 120.655899\n",
      "Train Epoch: 7 [6400/10000 (64%)]\tLoss: 102.181313\n",
      "Train Epoch: 7 [9600/10000 (96%)]\tLoss: 112.213272\n",
      "Train Epoch: 8 [0/10000 (0%)]\tLoss: 118.561172\n",
      "Train Epoch: 8 [3200/10000 (32%)]\tLoss: 118.736267\n",
      "Train Epoch: 8 [6400/10000 (64%)]\tLoss: 107.762688\n",
      "Train Epoch: 8 [9600/10000 (96%)]\tLoss: 117.298111\n",
      "Train Epoch: 9 [0/10000 (0%)]\tLoss: 107.810677\n",
      "Train Epoch: 9 [3200/10000 (32%)]\tLoss: 112.815262\n",
      "Train Epoch: 9 [6400/10000 (64%)]\tLoss: 115.928169\n",
      "Train Epoch: 9 [9600/10000 (96%)]\tLoss: 111.999664\n",
      "Train Epoch: 10 [0/10000 (0%)]\tLoss: 96.213547\n",
      "Train Epoch: 10 [3200/10000 (32%)]\tLoss: 111.852806\n",
      "Train Epoch: 10 [6400/10000 (64%)]\tLoss: 106.603638\n",
      "Train Epoch: 10 [9600/10000 (96%)]\tLoss: 108.475433\n",
      "training time = 112.789622\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "use_cuda = False\n",
    "input_size = 28 * 28\n",
    "units = 400\n",
    "batch_size = 32\n",
    "latent_size = 20 # z dim\n",
    "num_classes = 10\n",
    "num_epochs = 10\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "dataset = datasets.MNIST(\n",
    "    './data',  train=True, download=True,\n",
    "    transform=transforms.ToTensor())\n",
    "train_dataset = torch.utils.data.Subset(dataset, indices=range(10000))\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "model = CVAE(input_size, latent_size, num_classes)\n",
    "\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "\n",
    "# Note: You will get an ValueError here if you haven't implemented anything\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "start = time.time()\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    train(epoch, model, train_loader, optimizer, num_classes, use_cuda)\n",
    "print('training time = %f'%(time.time() - start)) # should take less than 5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 181,
     "status": "error",
     "timestamp": 1584547412300,
     "user": {
      "displayName": "Sungryull Sohn",
      "photoUrl": "",
      "userId": "06647518667646069751"
     },
     "user_tz": 240
    },
    "id": "16nKjAMSYeyo",
    "outputId": "3cbfcdb1-c1db-4c55-ff87-34e1ea54c7cf"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate images with condition labels\n",
    "c = torch.eye(num_classes, num_classes) # [one hot labels for 0-9]\n",
    "c = to_var(c, use_cuda)\n",
    "z = to_var(torch.randn(num_classes, latent_size), use_cuda)\n",
    "samples = model.generation_model(z, c).data.cpu().numpy()\n",
    "\n",
    "fig = plt.figure(figsize=(10, 1))\n",
    "gs = gridspec.GridSpec(1, 10)\n",
    "gs.update(wspace=0.05, hspace=0.05)\n",
    "for i, sample in enumerate(samples):\n",
    "    ax = plt.subplot(gs[i])\n",
    "    plt.axis('off')\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_aspect('equal')\n",
    "    plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pcrxsGtfYrhb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPWTelZADQlTvL/JjB3k/Eh",
   "collapsed_sections": [],
   "name": "q5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
