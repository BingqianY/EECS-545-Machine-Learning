{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load data\n",
    "q2_data = np.load('q2_data/q2_data.npz')\n",
    "xtrain = q2_data['q2x_train']\n",
    "ytrain = q2_data['q2y_train']\n",
    "xtest = q2_data['q2x_test']\n",
    "ytest = q2_data['q2y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "w = np.zeros((xtrain.shape[1], num_classes))\n",
    "grad_w = w.copy()\n",
    "def grad(w, grad_w, xtrain, ytrain, num_classes):\n",
    "    for m in range(num_classes-1):\n",
    "        summation = np.zeros((xtrain.shape[1],1))\n",
    "        mul = np.zeros((xtrain.shape[1],1))\n",
    "        for i in range(xtrain.shape[0]):\n",
    "            den = 0\n",
    "            for j in range(num_classes-1):\n",
    "                den = den + np.exp(np.dot(w[:,j].reshape(-1,1).T, xtrain[i,:].reshape(-1,1)))\n",
    "                if ytrain[i] == m+1:\n",
    "                    value = 1 - np.exp(np.dot(w[:,m].reshape(-1,1).T, xtrain[i, :].reshape(-1,1)))/(1+den)\n",
    "                else:\n",
    "                    value = - np.exp(np.dot(w[:,m], xtrain[i, :]))/(1+den)\n",
    "            mul = xtrain[i,:]*value\n",
    "            mul = mul.T\n",
    "            summation += mul\n",
    "            #summation = summation.reshape(-1,)\n",
    "        grad_w[:, m] = summation.reshape(-1,)\n",
    "    return grad_w\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.zeros((xtrain.shape[1], num_classes))\n",
    "grad_w = w.copy()\n",
    "num_classes = 3\n",
    "for num_iterations in range(1000):\n",
    "    alpha = 0.0005\n",
    "    grad_w = grad(w, grad_w, xtrain, ytrain, num_classes)\n",
    "    w = w + alpha*grad_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = np.zeros((ytrain.shape[0],1))\n",
    "for i in range(xtrain.shape[0]):\n",
    "    p = np.zeros((num_classes,1))\n",
    "    for m in range(num_classes):\n",
    "        den = 0\n",
    "        for j in range(num_classes-1):\n",
    "            den = den + np.exp(np.dot(w[:,j].reshape(-1,1).T, xtrain[i,:].reshape(-1,1)))\n",
    "        p[m] = np.exp(np.dot(w[:,m].reshape(-1,1).T, xtrain[i,:].reshape(-1,1)))/(1+den)\n",
    "    l = p.argmax()\n",
    "    labels_train[i] = l+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = np.zeros((ytest.shape[0],1))\n",
    "for i in range(xtest.shape[0]):\n",
    "    p = np.zeros((num_classes,1))\n",
    "    for m in range(num_classes):\n",
    "        for j in range(num_classes-1):\n",
    "            den = den + np.exp(np.dot(w[:,j].reshape(-1,1).T, xtest[i,:].reshape(-1,1)))\n",
    "        p[m] = np.exp(np.dot(w[:,m].reshape(-1,1).T, xtest[i,:].reshape(-1,1)))/(1+den)\n",
    "    l = p.argmax()\n",
    "    labels_test[i] = l+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification accuracy for training data is 97% \n",
      "The classification accuracy for testing data is 94% \n"
     ]
    }
   ],
   "source": [
    "accuracy = sum(a == b for a,b in zip(labels_train, ytrain))\n",
    "class_acc = (accuracy/ytrain.shape[0])*100\n",
    "print('The classification accuracy for training data is %g%% ' %class_acc)\n",
    "accuracy = sum(a == b for a,b in zip(labels_test, ytest))\n",
    "class_acc = (accuracy/ytest.shape[0])*100\n",
    "print('The classification accuracy for testing data is %g%% ' %class_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.97\n",
      "Testing accuracy: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nidhi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Nidhi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Comparision with sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def default_accuracy (pred, ytrain):\n",
    "    j=0\n",
    "    for i in range(len(ytrain)):\n",
    "        if pred[i] == ytrain[i]:\n",
    "            j +=1\n",
    "    acc = j/float(len(ytrain))\n",
    "    return acc\n",
    "\n",
    "classifier = LogisticRegression(max_iter=300)\n",
    "classifier.fit(xtrain, ytrain.reshape(-1,))\n",
    "ypred=classifier.predict(xtrain)\n",
    "print('Training accuracy:', default_accuracy(ypred, ytrain.reshape(-1,)))\n",
    "ypred=classifier.predict(xtest)\n",
    "print('Testing accuracy:', default_accuracy(ypred, ytest.reshape(-1,)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
